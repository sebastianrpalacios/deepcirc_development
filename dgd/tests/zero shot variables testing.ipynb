{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f80a992c",
   "metadata": {},
   "source": [
    "### Analysis of zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39297c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading action motifs. There are 15928 unique motifs.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -coding: utf-8 -\n",
    "\"\"\"\n",
    "Runs three evaluation tracks (trained, untrained-same-arch, random) with an\n",
    "ActionMasker-wrapped DRL3env and a shared registry.\n",
    "\n",
    "CHANGELOG (relative to your original script):\n",
    "- best_energy_in_episode in the CSV is now read directly from the env's\n",
    "  per-episode tracker (`_best_energy_in_episode`), i.e., independent of what\n",
    "  was (or wasn't) stored in the registry in that episode.\n",
    "- During policy rollout, we attempt to pass `action_masks` to MaskablePPO.predict()\n",
    "  (with a safe fallback for sb3-contrib versions that don't accept it).\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import argparse\n",
    "import csv\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import networkx as nx\n",
    "\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "\n",
    "# env + utils from your repo\n",
    "from dgd.environments.drl3env_loader5_with_trajectories import (\n",
    "    DRL3env,\n",
    "    _compute_truth_key,\n",
    "    _compute_hash,\n",
    "    _apply_implicit_or,\n",
    ")\n",
    "from dgd.utils.utils5 import load_graph_pickle, energy_score, check_implicit_OR_existence_v3\n",
    "\n",
    "def save_episode_trajectory(env, out_dir: Path, episode: int, track_name: str):\n",
    "    \"\"\"Dump the current episode's trajectory from the underlying env to JSON.\"\"\"\n",
    "    get_traj = None\n",
    "    try:\n",
    "        get_traj = env.get_wrapper_attr(\"get_trajectory\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    if get_traj is None:\n",
    "        # Not wrapped, maybe it's the base env\n",
    "        get_traj = getattr(env, \"get_trajectory\", None)\n",
    "\n",
    "    if get_traj is None:\n",
    "        return  # no-op if env doesn't support it\n",
    "\n",
    "    steps = get_traj()\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / f\"ep_{episode:04d}.json\"\n",
    "    payload = {\"episode\": int(episode), \"track\": track_name, \"steps\": steps}\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, indent=2)\n",
    "\n",
    "def mask_fn(env):\n",
    "    return env.action_masks()\n",
    "\n",
    "def _to_int_action(action):\n",
    "    if isinstance(action, np.ndarray):\n",
    "        if action.shape == ():\n",
    "            return int(action.item())\n",
    "        return int(action.reshape(-1)[0])\n",
    "    return int(action)\n",
    "\n",
    "def _to_graph(x):\n",
    "    \"\"\"Return a NetworkX graph whether x is already a graph or a node_link JSON dict.\"\"\"\n",
    "    if isinstance(x, (nx.Graph, nx.DiGraph)):\n",
    "        return x\n",
    "    if isinstance(x, dict):\n",
    "        return nx.node_link_graph(x)\n",
    "    try:\n",
    "        return nx.node_link_graph(x)\n",
    "    except Exception:\n",
    "        raise TypeError(f\"Cannot convert object of type {type(x)} to NetworkX graph\")\n",
    "\n",
    "def _get_best_energy_in_episode(env):\n",
    "    \"\"\"\n",
    "    Fetch the env's per-episode minimum energy (tracked internally by DRL3env)\n",
    "    after an episode finishes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        val = env.get_wrapper_attr(\"_best_energy_in_episode\")\n",
    "        if val is not None:\n",
    "            return float(val)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        return float(env.unwrapped._best_energy_in_episode)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def save_run_meta(out_dir=None, filename=\"run_metadata_simple.json\"):\n",
    "    \"\"\"\n",
    "    Writes a tiny JSON receipt with (1) UTC timestamp, (2) ALL CLI flags,\n",
    "    and (3) imported top-level modules (+version when available).\n",
    "\n",
    "    Usage:\n",
    "        save_run_meta(out_dir=getattr(args, \"output_folder_name\", \".\"))\n",
    "        # or just: save_run_meta()  # auto-uses --output_folder_name if present\n",
    "    \"\"\"\n",
    "    import sys, json\n",
    "    from datetime import datetime, timezone\n",
    "    from pathlib import Path\n",
    "\n",
    "    # timestamp\n",
    "    ts = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "    # capture CLI (raw + schema-free parse)\n",
    "    argv = sys.argv[1:]\n",
    "    flags, positionals = {}, []\n",
    "    i = 0\n",
    "    while i < len(argv):\n",
    "        tok = argv[i]\n",
    "        if tok.startswith(\"--\"):\n",
    "            key, val = tok[2:], True\n",
    "            if \"=\" in key:\n",
    "                key, val = key.split(\"=\", 1)\n",
    "            elif i + 1 < len(argv) and not argv[i + 1].startswith(\"-\"):\n",
    "                val = argv[i + 1]; i += 1\n",
    "            flags.setdefault(key, []).append(val)\n",
    "        elif tok.startswith(\"-\") and len(tok) > 1:\n",
    "            rest = tok[1:]\n",
    "            if \"=\" in rest:\n",
    "                k, val = rest.split(\"=\", 1); flags.setdefault(k, []).append(val)\n",
    "            elif len(rest) == 1 and i + 1 < len(argv) and not argv[i + 1].startswith(\"-\"):\n",
    "                flags.setdefault(rest, []).append(argv[i + 1]); i += 1\n",
    "            else:\n",
    "                for ch in rest: flags.setdefault(ch, []).append(True)\n",
    "        else:\n",
    "            positionals.append(tok)\n",
    "        i += 1\n",
    "\n",
    "    # imports snapshot (top-level names, with version if available)\n",
    "    imps, seen = [], set()\n",
    "    for name, mod in list(sys.modules.items()):\n",
    "        if not mod or getattr(mod, \"__file__\", None) is None:  # skip builtins/frozen\n",
    "            continue\n",
    "        top = name.split(\".\", 1)[0]\n",
    "        if top in seen: \n",
    "            continue\n",
    "        seen.add(top)\n",
    "        ver = getattr(mod, \"__version__\", None)\n",
    "        if ver is None:\n",
    "            base = sys.modules.get(top)\n",
    "            ver = getattr(base, \"__version__\", None) if base else None\n",
    "        imps.append({\"name\": top, **({\"version\": str(ver)} if ver else {})})\n",
    "    imps.sort(key=lambda x: x[\"name\"])\n",
    "\n",
    "    # choose output dir\n",
    "    if out_dir is None:\n",
    "        out_dir = (flags.get(\"output_folder_name\", [\".\"])[-1]) if \"output_folder_name\" in flags else \".\"\n",
    "    out_path = Path(out_dir); out_path.mkdir(parents=True, exist_ok=True)\n",
    "    out_file = out_path / filename\n",
    "\n",
    "    # write\n",
    "    payload = {\n",
    "        \"timestamp_iso_utc\": ts,\n",
    "        \"cli\": {\"raw\": argv, \"flags\": flags, \"positionals\": positionals},\n",
    "        \"imports\": imps,\n",
    "    }\n",
    "    with out_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, indent=2)\n",
    "    print(f\"[meta] wrote {out_file}\")\n",
    "    return str(out_file)\n",
    "\n",
    "# Registry helpers\n",
    "def init_shared_registry(manager, seed_graphs, lock):\n",
    "    \"\"\"\n",
    "    Create a Manager dict and pre-seed it with the initial graphs.\n",
    "    LIVE registry stores GRAPHS (not JSON), as tuples: (canon_graph, orig_graph, energy_float).\n",
    "    \"\"\"\n",
    "    reg = manager.dict()\n",
    "    with lock:\n",
    "        for G in seed_graphs:\n",
    "            canon = _apply_implicit_or(G.copy())\n",
    "            e, _ = energy_score(G, check_implicit_OR_existence_v3)\n",
    "            key = _compute_hash(canon)\n",
    "            bucket = reg.get(key, [])\n",
    "            bucket.append((canon, G.copy(), float(e)))\n",
    "            reg[key] = bucket\n",
    "    return reg\n",
    "\n",
    "def save_registry_pickle(registry, lock, path: Path):\n",
    "    \"\"\"Write the shared registry to a pickle safely: convert graphs â†’ node_link JSON.\"\"\"\n",
    "    plain = {}\n",
    "    with lock:\n",
    "        for k, bucket in registry.items():\n",
    "            json_bucket = []\n",
    "            for canon_g, orig_g, e in bucket:\n",
    "                canon_g = _to_graph(canon_g)\n",
    "                orig_g = _to_graph(orig_g)\n",
    "                json_bucket.append((nx.node_link_data(canon_g), nx.node_link_data(orig_g), float(e)))\n",
    "            plain[k] = json_bucket\n",
    "    with path.open(\"wb\") as f:\n",
    "        pickle.dump(plain, f)\n",
    "\n",
    "def save_registry_summary_csv(registry, lock, path: Path):\n",
    "    \"\"\"\n",
    "    Write a CSV summary with one row per registry entry (NOT per-episode).\n",
    "    Columns: hash, energy, size (nodes) of ORIGINAL graph.\n",
    "    \"\"\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open(\"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"hash\", \"energy\", \"size\"])\n",
    "        with lock:\n",
    "            for h, bucket in registry.items():\n",
    "                for _, orig_item, e in bucket:\n",
    "                    G = _to_graph(orig_item)\n",
    "                    w.writerow([h, float(e), G.number_of_nodes()])\n",
    "\n",
    "def _snapshot_registry_counts(registry, lock):\n",
    "    \"\"\"Map hash -> count of items currently in that bucket.\"\"\"\n",
    "    with lock:\n",
    "        return {h: len(bucket) for h, bucket in registry.items()}\n",
    "\n",
    "def _best_new_energy_since(registry, lock, snapshot_counts):\n",
    "    \"\"\"\n",
    "    Among entries added to the registry after the snapshot, return:\n",
    "    (min_new_energy, new_items_count). If nothing new, returns (None, 0).\n",
    "    \"\"\"\n",
    "    min_e = None\n",
    "    new_items = 0\n",
    "    with lock:\n",
    "        for h, bucket in registry.items():\n",
    "            start = snapshot_counts.get(h, 0)\n",
    "            for _, _, e in bucket[start:]:\n",
    "                new_items += 1\n",
    "                min_e = e if (min_e is None or e < min_e) else min_e\n",
    "    return min_e, new_items\n",
    "\n",
    "def _global_best_energy(registry, lock):\n",
    "    \"\"\"Minimum energy seen anywhere in the registry at call time.\"\"\"\n",
    "    best = None\n",
    "    with lock:\n",
    "        for _, bucket in registry.items():\n",
    "            for _, _, e in bucket:\n",
    "                best = e if (best is None or e < best) else best\n",
    "    return best\n",
    "\n",
    "def _append_episode_metrics_row(path: Path, episode: int, best_in_ep, best_so_far, new_graphs: int):\n",
    "    \"\"\"\n",
    "    Append one row to episode_metrics.csv with:\n",
    "    episode, best_energy_in_episode, best_energy_so_far, num_new_graphs\n",
    "    \"\"\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    new_file = not path.exists()\n",
    "    with path.open(\"a\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        if new_file:\n",
    "            w.writerow([\"episode\", \"best_energy_in_episode\", \"best_energy_so_far\", \"num_new_graphs\"])\n",
    "        w.writerow([\n",
    "            episode,\n",
    "            \"\" if best_in_ep is None else float(best_in_ep),\n",
    "            \"\" if best_so_far is None else float(best_so_far),\n",
    "            int(new_graphs),\n",
    "        ])\n",
    "\n",
    "def run_episode_with_policy(model, env, deterministic, ep_seed=None):\n",
    "    # reproducible per-episode reset\n",
    "    try:\n",
    "        obs, _ = env.reset(seed=ep_seed)\n",
    "    except TypeError:\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        # use action mask if available; safe fallback for older sb3-contrib\n",
    "\n",
    "        mask = env.get_wrapper_attr(\"action_masks\")()\n",
    "\n",
    "        action, _ = model.predict(obs, deterministic=deterministic, action_masks=mask)\n",
    "\n",
    "        action = _to_int_action(action)\n",
    "        \n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        done = terminated or truncated\n",
    "\n",
    "def run_episode_random_masked(env, ep_seed=None):\n",
    "    try:\n",
    "        obs, _ = env.reset(seed=ep_seed)\n",
    "    except TypeError:\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "    rng = np.random.default_rng(ep_seed)\n",
    "    done = False\n",
    "    while not done:\n",
    "        mask = env.get_wrapper_attr(\"action_masks\")()  # boolean mask\n",
    "        valid = np.flatnonzero(mask)\n",
    "        action = int(rng.choice(valid))\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "# Env factory \n",
    "def build_env_with_registry(seed_graphs, max_nodes, max_steps, existing_keys,\n",
    "                            registry, registry_lock, best_energy_across_workers,\n",
    "                            registry_sampling=True, initial_state_sampling_factor=0):\n",
    "    base_env = DRL3env(\n",
    "        max_nodes=max_nodes,\n",
    "        graphs=seed_graphs,\n",
    "        shared_registry=registry,\n",
    "        registry_lock=registry_lock,\n",
    "        store_every_new_graph=True,\n",
    "        sampling_from_shared_registry=registry_sampling,\n",
    "        registry_read_only=False,\n",
    "        max_steps=max_steps,\n",
    "        enable_full_graph_replacement=True,\n",
    "        show_plots=False,\n",
    "        log_info=False,\n",
    "        strict_iso_check=False,\n",
    "        initial_state_sampling_factor=initial_state_sampling_factor,\n",
    "        existing_keys=existing_keys,\n",
    "        best_energy_across_workers=best_energy_across_workers,  # required when using a shared registry\n",
    "    )    \n",
    "    try:\n",
    "        base_env.start_trajectory_logging(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return ActionMasker(base_env, mask_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c410c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = argparse.ArgumentParser(\n",
    "    description=(\n",
    "        \"Trained + Random(masked) + Untrained(masked) using a shared registry (single worker). \"\n",
    "        \"Also logs per-episode best energy (from env) and running best to CSV.\"\n",
    "    )\n",
    ")\n",
    "p.add_argument(\"--model_path\", help=\"Path to trained_model.zip\")\n",
    "p.add_argument(\"--seed_files\", nargs=\"+\", help=\"One or more seed .pkl graph files\")\n",
    "p.add_argument(\"--output_folder_name\", help=\"Base output folder\")\n",
    "p.add_argument(\"--episodes\", type=int, default=100)\n",
    "p.add_argument(\"--max_nodes\", type=int, default=100)\n",
    "p.add_argument(\"--max_steps\", type=int, default=10)\n",
    "p.add_argument('--initial_state_sampling_factor', type=float, default=0,\n",
    "                help='Factor for implementing weighted sampling of initial states')\n",
    "# default=False => omit -> stochastic; add -> greedy (applies to trained & untrained)\n",
    "p.add_argument(\"--deterministic\", action=\"store_true\", default=False)\n",
    "p.add_argument(\"--seed\", type=int, default=123, help=\"Base RNG seed for reproducibility\")\n",
    "args = p.parse_args([])\n",
    "\n",
    "args.model_path = \"/home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/scripts/runs/Fig3_4input_4000_logic_functions_registry_sampling_drl3env_loader5_v2/seed_1/trained_model.zip\"\n",
    "\n",
    "ID = \"0x0239\"\n",
    "args.seed_files = [f\"/home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/dgd/data/NIGs_4_inputs/{ID}_NIG_unoptimized.pkl\"]\n",
    "args.output_folder_name = \"/home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/stratch\"\n",
    "args.episodes = 10\n",
    "args.max_nodes = 100\n",
    "args.max_steps = 10\n",
    "args.initial_state_sampling_factor = 3\n",
    "#args.deterministic\n",
    "args.seed = 123\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37d8e4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using 1 seed file(s):\n",
      " - /home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/dgd/data/NIGs_4_inputs/0x0239_NIG_unoptimized.pkl\n",
      "[INFO] existing_keys initialized with 1 key(s)\n"
     ]
    }
   ],
   "source": [
    "base_out = Path(args.output_folder_name)\n",
    "(base_out / \"trained_masked\").mkdir(parents=True, exist_ok=True)\n",
    "(base_out / \"trained_masked\" / \"trajectories\").mkdir(parents=True, exist_ok=True)\n",
    "(base_out / \"untrained_masked\").mkdir(parents=True, exist_ok=True)\n",
    "(base_out / \"untrained_masked\" / \"trajectories\").mkdir(parents=True, exist_ok=True)\n",
    "(base_out / \"random_masked\").mkdir(parents=True, exist_ok=True)\n",
    "(base_out / \"random_masked\" / \"trajectories\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# global seeding\n",
    "import random\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "th.manual_seed(args.seed)\n",
    "\n",
    "# load seeds\n",
    "seed_paths = [str(Path(s)) for s in args.seed_files]\n",
    "print(f\"[INFO] Using {len(seed_paths)} seed file(s):\")\n",
    "for fp in seed_paths:\n",
    "    print(\" -\", fp)\n",
    "G_initial_states = [load_graph_pickle(fp) for fp in seed_paths]\n",
    "existing_keys = {_compute_truth_key(g) for g in G_initial_states}\n",
    "print(f\"[INFO] existing_keys initialized with {len(existing_keys)} key(s)\")\n",
    "\n",
    "device = \"cuda\" if th.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# TRACK 1: TRAINED (masked, registry) \n",
    "out_dir1 = base_out / \"trained_masked\"\n",
    "\n",
    "( out_dir1 / \"trajectories\" ).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mgr1 = multiprocessing.Manager()\n",
    "lock1 = mgr1.Lock()\n",
    "best1 = mgr1.Value('d', float('inf'))  # shared \"best energy\" (used by env)\n",
    "registry1 = init_shared_registry(mgr1, G_initial_states, lock1)  # pre-seed with initial graphs\n",
    "\n",
    "env1 = build_env_with_registry(\n",
    "    G_initial_states, args.max_nodes, args.max_steps,\n",
    "    existing_keys, registry1, lock1, best1,\n",
    "    registry_sampling=True, initial_state_sampling_factor=args.initial_state_sampling_factor\n",
    ")\n",
    "trained = MaskablePPO.load(args.model_path, env=env1, device=device)\n",
    "\n",
    "metrics_csv1 = out_dir1 / \"trained_episode_metrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "391a907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env1.reset(seed=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "329c3296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_features': array([[0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], dtype=float32),\n",
       " 'adj_matrix': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c040b802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = env1.get_wrapper_attr(\"action_masks\")()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "392d0883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(8205)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#action, _ = trained.predict(obs, deterministic=False, action_masks=mask)\n",
    "action, _ = trained.predict(obs, deterministic=False)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c500238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1013"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_to_int_action(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6ceb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, reward, terminated, truncated, info = env1.step(_to_int_action(action))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45d64fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_features': array([[0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], dtype=float32),\n",
       " 'adj_matrix': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a36aa573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6973"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env1.action_space.sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
