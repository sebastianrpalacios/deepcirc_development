{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d610b5c0",
   "metadata": {},
   "source": [
    "To launch in SuperCloud from a Computed Node\n",
    "\n",
    "LLsub -i full #for an exclusive node\n",
    "\n",
    "LLsub -i -s 40 #for node with 40 CPUs\n",
    "\n",
    "LLsub -i -s 40 -g volta:1 #for node with 40 CPUs and 1 Volta GPU\n",
    "\n",
    "salloc  --job-name=interactive --qos=high --time=02:00:00 --partition=debug-gpu --gres=gpu:volta:1 --cpus-per-task=40 srun    --pty bash -i\n",
    "\n",
    "salloc  --job-name=interactive --qos=high --time=02:00:00 --partition=debug-cpu --cpus-per-task=40 srun  --pty bash -i\n",
    "\n",
    "LLsub -i full\n",
    "\n",
    "module load anaconda/2023a-pytorch\n",
    "\n",
    "jupyter lab --no-browser --ip=0.0.0.0 --port=8890"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0f4712",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading action motifs. There are 15928 unique motifs.\n",
      "Loaded 200 graph paths from /home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/manuscript/trained_agents/GAT_MLP_with_scalars_200_logic_functions/selected_graphs.txt\n",
      "Model loaded on cuda\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/spalacios/.local/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m env \u001b[38;5;241m=\u001b[39m make_single_env(G)\n\u001b[1;32m     74\u001b[0m base_energy \u001b[38;5;241m=\u001b[39m energy_score(G, check_implicit_OR_existence_v3)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 75\u001b[0m mean_r, std_r \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EVAL_EPISODES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDETERMINISTIC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m rows\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: i,\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: fp,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd_reward\u001b[39m\u001b[38;5;124m\"\u001b[39m: std_r,\n\u001b[1;32m     84\u001b[0m })\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(graph_paths):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sb3_contrib/common/maskable/evaluation.py:94\u001b[0m, in \u001b[0;36mevaluate_policy\u001b[0;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn, use_masking)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (episode_counts \u001b[38;5;241m<\u001b[39m episode_count_targets)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_masking:\n\u001b[0;32m---> 94\u001b[0m         action_masks \u001b[38;5;241m=\u001b[39m \u001b[43mget_action_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m         actions, state \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m     96\u001b[0m             observations,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     97\u001b[0m             state\u001b[38;5;241m=\u001b[39mstates,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m             action_masks\u001b[38;5;241m=\u001b[39maction_masks,\n\u001b[1;32m    101\u001b[0m         )\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sb3_contrib/common/maskable/utils.py:17\u001b[0m, in \u001b[0;36mget_action_masks\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03mChecks whether gym env exposes a method returning invalid action masks\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m:param env: the Gym environment to get masks from\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m:return: A numpy array of the masks\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env, VecEnv):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack(\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEXPECTED_METHOD_NAME\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(env, EXPECTED_METHOD_NAME)()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:129\u001b[0m, in \u001b[0;36mDummyVecEnv.env_method\u001b[0;34m(self, method_name, indices, *method_args, **method_kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call instance methods of vectorized environments.\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m target_envs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_target_envs(indices)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mgetattr\u001b[39m(env_i, method_name)(\u001b[38;5;241m*\u001b[39mmethod_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmethod_kwargs) \u001b[38;5;28;01mfor\u001b[39;00m env_i \u001b[38;5;129;01min\u001b[39;00m target_envs]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:129\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call instance methods of vectorized environments.\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m target_envs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_target_envs(indices)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43menv_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m env_i \u001b[38;5;129;01min\u001b[39;00m target_envs]\n",
      "File \u001b[0;32m~/Designing complex biological circuits with deep neural networks/dgd/environments/drl3env_loader6.py:376\u001b[0m, in \u001b[0;36mDRL3env.action_masks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fanout_free_standalone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_solution, tgt, cut):\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m sg \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_subgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_solution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m([n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m sg \u001b[38;5;28;01mif\u001b[39;00m sg\u001b[38;5;241m.\u001b[39min_degree(n) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(cut):\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Designing complex biological circuits with deep neural networks/dgd/utils/utils5.py:2500\u001b[0m, in \u001b[0;36mgenerate_subgraph\u001b[0;34m(G, target_node, cut, draw)\u001b[0m\n\u001b[1;32m   2497\u001b[0m required_nodes \u001b[38;5;241m=\u001b[39m ancestors_of_target\u001b[38;5;241m.\u001b[39mintersection(descendants_of_cut)\u001b[38;5;241m.\u001b[39munion(cut, {target_node})\n\u001b[1;32m   2499\u001b[0m \u001b[38;5;66;03m# Create a subgraph with these nodes\u001b[39;00m\n\u001b[0;32m-> 2500\u001b[0m subgraph \u001b[38;5;241m=\u001b[39m \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequired_nodes\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2502\u001b[0m \u001b[38;5;66;03m# Step 3: Remove edges where both nodes are in 'cut'\u001b[39;00m\n\u001b[1;32m   2503\u001b[0m edges_to_remove \u001b[38;5;241m=\u001b[39m [(u, v) \u001b[38;5;28;01mfor\u001b[39;00m u, v \u001b[38;5;129;01min\u001b[39;00m subgraph\u001b[38;5;241m.\u001b[39medges() \u001b[38;5;28;01mif\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m cut \u001b[38;5;129;01mand\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m cut]\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2023a-pytorch/lib/python3.9/site-packages/networkx/classes/graph.py:1643\u001b[0m, in \u001b[0;36mGraph.copy\u001b[0;34m(self, as_view)\u001b[0m\n\u001b[1;32m   1641\u001b[0m G\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph)\n\u001b[1;32m   1642\u001b[0m G\u001b[38;5;241m.\u001b[39madd_nodes_from((n, d\u001b[38;5;241m.\u001b[39mcopy()) \u001b[38;5;28;01mfor\u001b[39;00m n, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m-> 1643\u001b[0m \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_edges_from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatadict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbrs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatadict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnbrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2023a-pytorch/lib/python3.9/site-packages/networkx/classes/digraph.py:768\u001b[0m, in \u001b[0;36mDiGraph.add_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_edges_from\u001b[39m(\u001b[38;5;28mself\u001b[39m, ebunch_to_add, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattr):\n\u001b[1;32m    714\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add all the edges in ebunch_to_add.\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;124;03m    >>> G.add_edges_from(list((5, n) for n in G.nodes))\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m ebunch_to_add:\n\u001b[1;32m    769\u001b[0m         ne \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(e)\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ne \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2023a-pytorch/lib/python3.9/site-packages/networkx/classes/graph.py:1644\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1641\u001b[0m G\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph)\n\u001b[1;32m   1642\u001b[0m G\u001b[38;5;241m.\u001b[39madd_nodes_from((n, d\u001b[38;5;241m.\u001b[39mcopy()) \u001b[38;5;28;01mfor\u001b[39;00m n, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m   1643\u001b[0m G\u001b[38;5;241m.\u001b[39madd_edges_from(\n\u001b[0;32m-> 1644\u001b[0m     (u, v, datadict\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m u, nbrs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adj\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v, datadict \u001b[38;5;129;01min\u001b[39;00m nbrs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1647\u001b[0m )\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- CONFIG: EDIT THESE ---\n",
    "MODEL_PATH   = \"/home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/manuscript/trained_agents/GAT_MLP_with_scalars_200_logic_functions/trained_model.zip\"\n",
    "SELECTED_GRAPHS_FILE = \"/home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/manuscript/trained_agents/GAT_MLP_with_scalars_200_logic_functions/selected_graphs.txt\"\n",
    "OUTPUT_CSV   = \"per_graph_eval.csv\"\n",
    "\n",
    "N_EVAL_EPISODES = 100     # use 10–20 for faster runs\n",
    "DETERMINISTIC = False\n",
    "MAX_STEPS = 10\n",
    "MAX_NODES = 100\n",
    "DEVICE = \"cuda\"  # or \"cpu\"\n",
    "# ----------------\n",
    "\n",
    "import os, pickle, re, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch as th\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
    "\n",
    "from dgd.environments.drl3env_loader6 import DRL3env, _compute_truth_key\n",
    "from dgd.utils.utils5 import energy_score, check_implicit_OR_existence_v3\n",
    "\n",
    "# --- Read the 4000 graph paths ---\n",
    "with open(SELECTED_GRAPHS_FILE, \"r\") as f:\n",
    "    lines = [l.strip() for l in f if l.strip().startswith(\"Selected\")]\n",
    "graph_paths = [l.split(\"Selected\")[-1].strip() for l in lines]\n",
    "print(f\"Loaded {len(graph_paths)} graph paths from {SELECTED_GRAPHS_FILE}\")\n",
    "\n",
    "# --- Helpers ---\n",
    "def load_graph_pickle(filename: str) -> nx.DiGraph:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        num_nodes, edges, node_attrs = pickle.load(f)\n",
    "    G = nx.DiGraph()\n",
    "    for node, attr in node_attrs.items():\n",
    "        G.add_node(node, type=attr) if attr is not None else G.add_node(node)\n",
    "    G.add_edges_from(edges)\n",
    "    return G\n",
    "\n",
    "def make_single_env(G: nx.DiGraph):\n",
    "    existing_keys = {_compute_truth_key(G)}\n",
    "    def _factory():\n",
    "        return DRL3env(\n",
    "            max_nodes=MAX_NODES,\n",
    "            graphs=[G],\n",
    "            enable_full_graph_replacement=True,\n",
    "            show_plots=False,\n",
    "            log_info=False,\n",
    "            strict_iso_check=False,\n",
    "            max_steps=MAX_STEPS,\n",
    "            registry_read_only=True,\n",
    "            existing_keys=existing_keys,\n",
    "        )\n",
    "    return make_vec_env(_factory, n_envs=1, vec_env_cls=DummyVecEnv, seed=0)\n",
    "\n",
    "# --- Load trained model ---\n",
    "use_cuda = (DEVICE == \"cuda\") and th.cuda.is_available()\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "model = MaskablePPO.load(MODEL_PATH, device=device)\n",
    "print(f\"Model loaded on {device}\")\n",
    "\n",
    "# --- Evaluate per graph ---\n",
    "rows = []\n",
    "for i, fp in enumerate(graph_paths, 1):\n",
    "    print(i)\n",
    "    try:\n",
    "        G = load_graph_pickle(fp)\n",
    "        env = make_single_env(G)\n",
    "\n",
    "        base_energy = energy_score(G, check_implicit_OR_existence_v3)[0]\n",
    "        mean_r, std_r = evaluate_policy(model, env, n_eval_episodes=N_EVAL_EPISODES, deterministic=DETERMINISTIC)\n",
    "\n",
    "        rows.append({\n",
    "            \"index\": i,\n",
    "            \"path\": fp,\n",
    "            \"hex_id\": re.search(r\"(0x[0-9A-Fa-f]+)_NIG\", os.path.basename(fp)).group(1),\n",
    "            \"baseline_energy\": base_energy,\n",
    "            \"mean_reward\": mean_r,\n",
    "            \"std_reward\": std_r,\n",
    "        })\n",
    "\n",
    "        if i % 50 == 0 or i == len(graph_paths):\n",
    "            print(f\"[{i}/{len(graph_paths)}] {os.path.basename(fp)} → mean_reward={mean_r:.3f}\")\n",
    "\n",
    "        env.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Skipping {fp}: {e}\")\n",
    "        rows.append({\"index\": i, \"path\": fp, \"hex_id\": None, \"baseline_energy\": np.nan, \"mean_reward\": np.nan, \"std_reward\": np.nan})\n",
    "\n",
    "# ------\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved results to {OUTPUT_CSV}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9040a",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "323d50dd",
   "metadata": {},
   "source": [
    "Load shared registry and evaluate there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff0abd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model on cuda\n",
      "Loading registry: /home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/manuscript/trained_agents/GAT_MLP_with_scalars_4000_logic_functions/final_shared_registry.pkl\n",
      "Registry buckets: 391728 | total entries: 391728\n",
      "Subsampled entries: 10000 (mode='count')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f080f322d964117a2428b31c265c784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rebuilding graphs:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuilt 10000 original graphs. Best energy in subsample: 2.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68470da99c2845e5b38c39c06ef2542e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building keys/light registry:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light registry buckets: 1470 (read-only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/spalacios/.local/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Registry sampling FAST — subsampled] episodes=100 det=False\n",
      "Mean reward = 9.225 | Std = 4.106\n",
      "Saved per-episode rewards to /home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/eval_from_registry_sampling.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>reward</th>\n",
       "      <th>length</th>\n",
       "      <th>deterministic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.703704</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode     reward  length  deterministic\n",
       "0        1  11.111111      10          False\n",
       "1        2   2.222222      10          False\n",
       "2        3   4.347826      10          False\n",
       "3        4  10.000000      10          False\n",
       "4        5   3.703704      10          False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- CONFIG: EDIT THESE ---\n",
    "MODEL_PATH    = \"/home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/manuscript/trained_agents/GAT_MLP_with_scalars_4000_logic_functions/trained_model.zip\"\n",
    "REGISTRY_PATH = \"/home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/manuscript/trained_agents/GAT_MLP_with_scalars_4000_logic_functions/final_shared_registry.pkl\"\n",
    "OUTPUT_CSV    = \"eval_from_registry_sampling.csv\"\n",
    "\n",
    "N_EVAL_EPISODES = 100\n",
    "DETERMINISTIC   = False\n",
    "MAX_STEPS       = 10\n",
    "MAX_NODES       = 100\n",
    "N_WORKERS       = 40          # set ~ to your CPU cores\n",
    "DEVICE          = \"cuda\"      # or \"cpu\"\n",
    "\n",
    "# --- Subsampling config ---\n",
    "SUBSAMPLE_MODE       = \"count\"   # \"fraction\", \"count\", or \"per_bucket\"\n",
    "SUBSAMPLE_FRACTION   = 0.01         # used if MODE == \"fraction\"\n",
    "SUBSAMPLE_COUNT      = 10000         # used if MODE == \"count\"\n",
    "SUBSAMPLE_PER_BUCKET = 3            # used if MODE == \"per_bucket\"\n",
    "SUBSAMPLE_SEED       = 42           # reproducibility\n",
    "# --------------------------\n",
    "\n",
    "import pickle, warnings, os, multiprocessing as mp\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import networkx as nx\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
    "\n",
    "from dgd.environments.drl3env_loader6 import DRL3env, _compute_truth_key\n",
    "\n",
    "# NEW: tqdm for progress bars (works in notebooks & terminals)\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(x, **kwargs):\n",
    "        return x\n",
    "\n",
    "def _rebuild_orig_graph(bucket_item):\n",
    "    \"\"\"Worker: take (canon_nl, orig_nl, e) → (orig_graph, e). Build ONLY orig.\"\"\"\n",
    "    canon_nl, orig_nl, e = bucket_item\n",
    "    orig_g = nx.node_link_graph(orig_nl)\n",
    "    return (orig_g, float(e))\n",
    "\n",
    "print(\"Loading model...\")\n",
    "use_cuda = (DEVICE == \"cuda\") and th.cuda.is_available()\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "model = MaskablePPO.load(MODEL_PATH, device=device)\n",
    "print(f\"Model on {device}\")\n",
    "\n",
    "print(f\"Loading registry: {REGISTRY_PATH}\")\n",
    "with open(REGISTRY_PATH, \"rb\") as f:\n",
    "    raw_reg = pickle.load(f)  # dict: key -> list[(canon_nl, orig_nl, e), ...]\n",
    "\n",
    "total_entries = sum(len(b) for b in raw_reg.values())\n",
    "print(f\"Registry buckets: {len(raw_reg)} | total entries: {total_entries}\")\n",
    "\n",
    "# -----------------\n",
    "# Subsample registry\n",
    "# -----------------\n",
    "rng = np.random.default_rng(SUBSAMPLE_SEED)\n",
    "\n",
    "if SUBSAMPLE_MODE == \"per_bucket\":\n",
    "    sampled_items = []\n",
    "    for bucket in raw_reg.values():\n",
    "        if not bucket:\n",
    "            continue\n",
    "        k = min(len(bucket), SUBSAMPLE_PER_BUCKET)\n",
    "        idxs = rng.choice(len(bucket), size=k, replace=False)\n",
    "        sampled_items.extend(bucket[i] for i in idxs)\n",
    "else:\n",
    "    all_items = [item for bucket in raw_reg.values() for item in bucket]\n",
    "    if SUBSAMPLE_MODE == \"fraction\":\n",
    "        k = max(1, int(len(all_items) * SUBSAMPLE_FRACTION))\n",
    "    elif SUBSAMPLE_MODE == \"count\":\n",
    "        k = min(SUBSAMPLE_COUNT, len(all_items))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown SUBSAMPLE_MODE: {SUBSAMPLE_MODE}\")\n",
    "    if k < len(all_items):\n",
    "        idxs = rng.choice(len(all_items), size=k, replace=False)\n",
    "        sampled_items = [all_items[i] for i in idxs]\n",
    "    else:\n",
    "        sampled_items = all_items\n",
    "\n",
    "if len(sampled_items) == 0:\n",
    "    raise RuntimeError(\"Subsampling resulted in 0 items. Adjust SUBSAMPLE_* settings.\")\n",
    "\n",
    "print(f\"Subsampled entries: {len(sampled_items)} (mode='{SUBSAMPLE_MODE}')\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Parallel rebuild of ONLY original graphs (fast)\n",
    "# ----------------------------------------------\n",
    "rebuilt = []\n",
    "best_energy = np.inf\n",
    "effective_workers = min(N_WORKERS, max(1, len(sampled_items)))\n",
    "with ProcessPoolExecutor(max_workers=effective_workers) as ex:\n",
    "    futures = [ex.submit(_rebuild_orig_graph, it) for it in sampled_items]\n",
    "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Rebuilding graphs\", smoothing=0.1):\n",
    "        try:\n",
    "            orig_g, e = fut.result()\n",
    "            rebuilt.append((orig_g, e))\n",
    "            if e < best_energy:\n",
    "                best_energy = e\n",
    "        except Exception as exc:\n",
    "            warnings.warn(f\"Skipping one registry item due to error: {exc}\")\n",
    "\n",
    "if len(rebuilt) == 0:\n",
    "    raise RuntimeError(\"No graphs were rebuilt successfully from the subsample.\")\n",
    "\n",
    "print(f\"Rebuilt {len(rebuilt)} original graphs. Best energy in subsample: {best_energy:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Build lightweight read-only \"registry\" using (orig as canon)\n",
    "# ---------------------------------------------------------\n",
    "light_registry = {}\n",
    "existing_keys = set()\n",
    "\n",
    "for orig_g, e in tqdm(rebuilt, desc=\"Building keys/light registry\", smoothing=0.1):\n",
    "    try:\n",
    "        key = _compute_truth_key(orig_g)\n",
    "        bucket = light_registry.setdefault(key, [])\n",
    "        bucket.append((orig_g, orig_g, e))  # (canon, orig, e) with canon=orig\n",
    "        existing_keys.add(key)\n",
    "    except Exception:\n",
    "        # skip unusual cases\n",
    "        pass\n",
    "\n",
    "if len(light_registry) == 0:\n",
    "    raise RuntimeError(\"Light registry is empty after rebuild. Nothing to sample from.\")\n",
    "\n",
    "print(f\"Light registry buckets: {len(light_registry)} (read-only)\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# REQUIRED BY DRL3env WHEN USING shared_registry:\n",
    "#   - registry_lock\n",
    "#   - best_energy_across_workers (shared double)\n",
    "# ---------------------------------------------------------\n",
    "REGISTRY_LOCK = mp.Lock()\n",
    "GLOBAL_BEST = mp.Value('d', best_energy if np.isfinite(best_energy) else 1e12)\n",
    "\n",
    "def make_registry_sampling_env():\n",
    "    # graphs=[]: rely on shared read-only registry for initial state sampling\n",
    "    return DRL3env(\n",
    "        max_nodes=MAX_NODES,\n",
    "        graphs=[],\n",
    "        enable_full_graph_replacement=True,\n",
    "        show_plots=False,\n",
    "        log_info=False,\n",
    "        max_steps=MAX_STEPS,\n",
    "        # read-only registry sampling\n",
    "        shared_registry=light_registry,\n",
    "        registry_lock=REGISTRY_LOCK,\n",
    "        best_energy_across_workers=GLOBAL_BEST,\n",
    "        store_every_new_graph=False,\n",
    "        sampling_from_shared_registry=True,\n",
    "        initial_state_sampling_factor=0,\n",
    "        strict_iso_check=False,\n",
    "        registry_read_only=True,\n",
    "        existing_keys=existing_keys,\n",
    "    )\n",
    "\n",
    "# Single-env evaluation with sampling from the (subsampled) shared registry\n",
    "env = make_vec_env(make_registry_sampling_env, n_envs=1, vec_env_cls=DummyVecEnv, seed=0)\n",
    "\n",
    "ep_rewards, ep_lengths = evaluate_policy(\n",
    "    model, env, n_eval_episodes=N_EVAL_EPISODES,\n",
    "    deterministic=DETERMINISTIC, return_episode_rewards=True\n",
    ")\n",
    "\n",
    "mean_r, std_r = float(np.mean(ep_rewards)), float(np.std(ep_rewards))\n",
    "print(f\"\\n[Registry sampling FAST — subsampled] episodes={N_EVAL_EPISODES} det={DETERMINISTIC}\")\n",
    "print(f\"Mean reward = {mean_r:.3f} | Std = {std_r:.3f}\")\n",
    "\n",
    "df_trained = pd.DataFrame({\n",
    "    \"episode\": np.arange(1, len(ep_rewards)+1),\n",
    "    \"reward\": ep_rewards,\n",
    "    \"length\": ep_lengths,\n",
    "    \"deterministic\": DETERMINISTIC,\n",
    "})\n",
    "df_trained.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved per-episode rewards to {Path(OUTPUT_CSV).resolve()}\")\n",
    "\n",
    "try:\n",
    "    display(df_trained.head())\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27f229",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved exact subsample to trained_run_sampled_items.pkl\n"
     ]
    }
   ],
   "source": [
    "with open(\"trained_run_sampled_items.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sampled_items, f)\n",
    "print(\"Saved exact subsample to trained_run_sampled_items.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb7405",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc494464",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded preselected sampled items: 10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b224aa19f57418096f5ee039723cb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rebuilding graphs:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuilt 10000 original graphs. Best energy in subsample: 2.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3249c6a3a5fb46ffa100e4b78ef9a15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building keys/light registry:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light registry buckets: 1470 (read-only)\n",
      "Inspecting saved model to copy architecture (not weights)...\n",
      "Policy class: MaskableMultiInputActorCriticPolicy | device: cuda\n",
      "Instantiating a fresh, UNTRAINED MaskablePPO model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/spalacios/.local/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Same subsample — UNTRAINED policy] episodes=100 det=False\n",
      "Mean reward = 4.789 | Std = 3.265\n",
      "Saved per-episode rewards to /home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/eval_from_registry_sampling_untrained.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>reward</th>\n",
       "      <th>length</th>\n",
       "      <th>deterministic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.127660</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode     reward  length  deterministic\n",
       "0        1   5.882353      10          False\n",
       "1        2   7.142857      10          False\n",
       "2        3  12.500000      10          False\n",
       "3        4   2.127660      10          False\n",
       "4        5   7.692308      10          False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- CONFIG: EDIT THESE ---\n",
    "MODEL_PATH    = \"/home/gridsan/spalacios/Designing complex biological circuits with deep neural networks/manuscript/trained_agents/GAT_MLP_with_scalars_4000_logic_functions/trained_model.zip\"\n",
    "SAMPLED_ITEMS_IN = \"trained_run_sampled_items.pkl\"   # <-- produced by the trained run\n",
    "OUTPUT_CSV    = \"eval_from_registry_sampling_untrained.csv\"\n",
    "\n",
    "N_EVAL_EPISODES = 100\n",
    "DETERMINISTIC   = False\n",
    "MAX_STEPS       = 10\n",
    "MAX_NODES       = 100\n",
    "N_WORKERS       = 40\n",
    "DEVICE          = \"cuda\"      # or \"cpu\"\n",
    "\n",
    "import pickle, warnings, os, multiprocessing as mp\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import networkx as nx\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
    "\n",
    "from dgd.environments.drl3env_loader6 import DRL3env, _compute_truth_key\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(x, **kwargs): return x\n",
    "\n",
    "def _rebuild_orig_graph(bucket_item):\n",
    "    canon_nl, orig_nl, e = bucket_item\n",
    "    orig_g = nx.node_link_graph(orig_nl)\n",
    "    return (orig_g, float(e))\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Step 0) Load the exact same subsample picked by trained run\n",
    "# --------------------------------------------------------\n",
    "if not os.path.exists(SAMPLED_ITEMS_IN):\n",
    "    raise FileNotFoundError(f\"Missing {SAMPLED_ITEMS_IN}. Run the trained script first.\")\n",
    "with open(SAMPLED_ITEMS_IN, \"rb\") as f:\n",
    "    sampled_items = pickle.load(f)\n",
    "if not isinstance(sampled_items, list) or not sampled_items:\n",
    "    raise RuntimeError(\"Loaded SAMPLED_ITEMS_IN is empty or invalid.\")\n",
    "\n",
    "print(f\"Loaded preselected sampled items: {len(sampled_items)}\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Rebuild ONLY original graphs (fast)\n",
    "# ----------------------------------------------\n",
    "rebuilt = []\n",
    "best_energy = np.inf\n",
    "effective_workers = min(N_WORKERS, max(1, len(sampled_items)))\n",
    "with ProcessPoolExecutor(max_workers=effective_workers) as ex:\n",
    "    futures = [ex.submit(_rebuild_orig_graph, it) for it in sampled_items]\n",
    "    for fut in tqdm(as_completed(futures), total=len(futures), desc=\"Rebuilding graphs\", smoothing=0.1):\n",
    "        try:\n",
    "            orig_g, e = fut.result()\n",
    "            rebuilt.append((orig_g, e))\n",
    "            if e < best_energy:\n",
    "                best_energy = e\n",
    "        except Exception as exc:\n",
    "            warnings.warn(f\"Skipping one registry item due to error: {exc}\")\n",
    "\n",
    "if len(rebuilt) == 0:\n",
    "    raise RuntimeError(\"No graphs were rebuilt successfully from the saved subsample.\")\n",
    "\n",
    "print(f\"Rebuilt {len(rebuilt)} original graphs. Best energy in subsample: {best_energy:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Build lightweight read-only registry (orig as canon)\n",
    "# ---------------------------------------------------------\n",
    "light_registry = {}\n",
    "existing_keys = set()\n",
    "for orig_g, e in tqdm(rebuilt, desc=\"Building keys/light registry\", smoothing=0.1):\n",
    "    try:\n",
    "        key = _compute_truth_key(orig_g)\n",
    "        bucket = light_registry.setdefault(key, [])\n",
    "        bucket.append((orig_g, orig_g, e))  # (canon, orig, e)\n",
    "        existing_keys.add(key)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if len(light_registry) == 0:\n",
    "    raise RuntimeError(\"Light registry is empty after rebuild.\")\n",
    "\n",
    "print(f\"Light registry buckets: {len(light_registry)} (read-only)\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# DRL3env shared state\n",
    "# ---------------------------------------------------------\n",
    "REGISTRY_LOCK = mp.Lock()\n",
    "GLOBAL_BEST = mp.Value('d', best_energy if np.isfinite(best_energy) else 1e12)\n",
    "\n",
    "def make_registry_sampling_env():\n",
    "    return DRL3env(\n",
    "        max_nodes=MAX_NODES,\n",
    "        graphs=[],\n",
    "        enable_full_graph_replacement=True,\n",
    "        show_plots=False,\n",
    "        log_info=False,\n",
    "        max_steps=MAX_STEPS,\n",
    "        shared_registry=light_registry,\n",
    "        registry_lock=REGISTRY_LOCK,\n",
    "        best_energy_across_workers=GLOBAL_BEST,\n",
    "        store_every_new_graph=False,\n",
    "        sampling_from_shared_registry=True,\n",
    "        initial_state_sampling_factor=0,\n",
    "        strict_iso_check=False,\n",
    "        registry_read_only=True,\n",
    "        existing_keys=existing_keys,\n",
    "    )\n",
    "\n",
    "env = make_vec_env(make_registry_sampling_env, n_envs=1, vec_env_cls=DummyVecEnv, seed=0)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# Instantiate a brand-new (UNTRAINED) model with same policy class/kwargs\n",
    "# --------------------------------------------------------\n",
    "print(\"Inspecting saved model to copy architecture (not weights)...\")\n",
    "use_cuda = (DEVICE == \"cuda\") and th.cuda.is_available()\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "\n",
    "_tmp_loaded = MaskablePPO.load(MODEL_PATH, device=device)\n",
    "policy_class = type(_tmp_loaded.policy)\n",
    "policy_kwargs = getattr(_tmp_loaded, \"policy_kwargs\", {}) or {}\n",
    "\n",
    "# Mirror common algo hyperparams when present\n",
    "algo_kwargs = {}\n",
    "for k in [\"n_steps\", \"batch_size\", \"n_epochs\", \"gamma\", \"gae_lambda\",\n",
    "          \"clip_range\", \"ent_coef\", \"vf_coef\", \"max_grad_norm\"]:\n",
    "    if hasattr(_tmp_loaded, k):\n",
    "        algo_kwargs[k] = getattr(_tmp_loaded, k)\n",
    "if hasattr(_tmp_loaded, \"learning_rate\"):\n",
    "    algo_kwargs[\"learning_rate\"] = _tmp_loaded.learning_rate\n",
    "elif hasattr(_tmp_loaded, \"lr_schedule\"):\n",
    "    try:\n",
    "        algo_kwargs[\"learning_rate\"] = float(_tmp_loaded.lr_schedule(1.0))\n",
    "    except Exception:\n",
    "        pass\n",
    "del _tmp_loaded\n",
    "\n",
    "print(f\"Policy class: {policy_class.__name__} | device: {device}\")\n",
    "print(\"Instantiating a fresh, UNTRAINED MaskablePPO model...\")\n",
    "model = MaskablePPO(\n",
    "    policy_class,\n",
    "    env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    device=device,\n",
    "    **algo_kwargs,\n",
    ")\n",
    "\n",
    "# Evaluate (no training)\n",
    "ep_rewards, ep_lengths = evaluate_policy(\n",
    "    model, env, n_eval_episodes=N_EVAL_EPISODES,\n",
    "    deterministic=DETERMINISTIC, return_episode_rewards=True\n",
    ")\n",
    "\n",
    "mean_r, std_r = float(np.mean(ep_rewards)), float(np.std(ep_rewards))\n",
    "print(f\"\\n[Same subsample — UNTRAINED policy] episodes={N_EVAL_EPISODES} det={DETERMINISTIC}\")\n",
    "print(f\"Mean reward = {mean_r:.3f} | Std = {std_r:.3f}\")\n",
    "\n",
    "df_untrained = pd.DataFrame({\n",
    "    \"episode\": np.arange(1, len(ep_rewards)+1),\n",
    "    \"reward\": ep_rewards,\n",
    "    \"length\": ep_lengths,\n",
    "    \"deterministic\": DETERMINISTIC,\n",
    "})\n",
    "df_untrained.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved per-episode rewards to {Path(OUTPUT_CSV).resolve()}\")\n",
    "\n",
    "try:\n",
    "    display(df_untrained.head())\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2dd18",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adab692",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3625266b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
