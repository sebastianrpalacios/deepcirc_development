{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09894e8d-7d56-4aa5-81dd-027851fd7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgd.utils.utils5 import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65584202-7e9e-409b-9ea0-cb65027e58a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fanout_free(G, target_node, cut):\n",
    "    \"\"\"Check if the cut is fanout-free\"\"\"\n",
    "\n",
    "    #Get all the nodes in G that are both ancestors of target_node and decendants of nodes 'cut'. The name of that set of nodes is 'cone'. \n",
    "    # Step 1: Find ancestors of target_node\n",
    "    ancestors_of_target = nx.ancestors(G, target_node)\n",
    "    # Step 2: Find descendants of all nodes in 'cut'\n",
    "    descendants_of_cut = set()\n",
    "    for node in cut:\n",
    "        descendants_of_cut.update(nx.descendants(G, node))        \n",
    "    # Step 3: Determine the 'cone'\n",
    "    cone = ancestors_of_target.intersection(descendants_of_cut)\n",
    "\n",
    "    #In G, check that nodes in 'cone' have no edges to a node not in the cone, but allow edges to target_node.\n",
    "    # Step 4: Check that nodes in 'cone' are only directly connected to nodes within 'cone', but allow edges to target_node.\n",
    "    fanout_free = True\n",
    "    for node in cone:\n",
    "        # Check outgoing edges from each node in the cone\n",
    "        for successor in G.successors(node):\n",
    "            if successor not in cone and successor != target_node:\n",
    "                # If a successor is not in the cone and is not the target_node, the cut is not fanout-free\n",
    "                fanout_free = False\n",
    "                #print(f\"Node {node} has an outgoing edge to node {successor}, which is outside the cone and is not the target_node.\")\n",
    "                return fanout_free  # Can immediately return as we found a violation\n",
    "\n",
    "    return fanout_free\n",
    "\n",
    "def generate_random_initial_states_multi_input(G_list, number_of_states, precomputed_graphs_1_input, graphs_library_1_input, precomputed_graphs_2_input, graphs_library_2_input, precomputed_graphs_3_input, graphs_library_3_input, precomputed_graphs_4_input, graphs_library_4_input):\n",
    "    #random_initial_states_list = [G.copy()]\n",
    "    random_initial_states_list = G_list\n",
    "    \n",
    "    # Initialize the progress bar\n",
    "    pbar = tqdm(total=number_of_states, desc=\"Generating Random Initial States\", unit=\"state\")\n",
    "    \n",
    "    while len(random_initial_states_list) < number_of_states + 1:\n",
    "        current_solution = random.choice(random_initial_states_list)\n",
    "    \n",
    "        # Choose a random target node, excluding specified nodes\n",
    "        excluded_nodes = [0, 1, 2, 3]  # Assuming these are input nodes\n",
    "        target_node = random.choice([node for node in current_solution.nodes() if node not in excluded_nodes])\n",
    "\n",
    "        select_cut_size_n = random.choice([1, 2, 3, 4])\n",
    "\n",
    "        #feasible_cuts = find_feasible_cuts(current_solution, target_node, max_cut_size=select_cut_size_n, filter_redundant=True)\n",
    "        feasible_cuts = exhaustive_cut_enumeration_dag(current_solution, select_cut_size_n, target_node = target_node, filter_redundant=True)\n",
    "        feasible_cuts_of_size_n = [cut for cut in feasible_cuts if len(cut) == select_cut_size_n]\n",
    "        \n",
    "\n",
    "        feasible_cuts_of_size_n = [cut for cut in feasible_cuts_of_size_n if is_fanout_free(current_solution, target_node, cut) == True]\n",
    "\n",
    "        if not feasible_cuts_of_size_n:\n",
    "            continue  # Skip iteration if no suitable cut found\n",
    "\n",
    "        cut = random.choice(feasible_cuts_of_size_n)\n",
    "        subgraph = generate_subgraph(current_solution, target_node, cut, draw=False)\n",
    "        \n",
    "        # Filter out the trivial cut (subgraph is only cut + target_node)\n",
    "        cut_set = set(cut)\n",
    "        cut_set.add(target_node)\n",
    "        if len(subgraph.nodes()) == len(cut_set):\n",
    "            continue\n",
    "\n",
    "        # Calculate truth table and attempt to get a replacement graph from library\n",
    "        if len([node for node in subgraph.nodes() if subgraph.in_degree(node) == 0]) == len(cut):\n",
    "            truth_table = calculate_truth_table(subgraph)\n",
    "            binary_str = ''.join(str(output[0]) for inputs, output in sorted(truth_table.items()))\n",
    "            truth_table_int = int(binary_str, 2)\n",
    "\n",
    "            if select_cut_size_n == 1:\n",
    "                # Check if the truth table integer is in the graphs library\n",
    "                if truth_table_int not in precomputed_graphs_1_input:\n",
    "                    continue  # Skip the rest of the iteration if no replacement graph is found\n",
    "\n",
    "                associated_graphs = precomputed_graphs_1_input[truth_table_int]\n",
    "                selected_graph_index = random.choice(associated_graphs)\n",
    "                replacement_graph = graphs_library_1_input[selected_graph_index]  \n",
    "\n",
    "            elif select_cut_size_n == 2:\n",
    "                # Check if the truth table integer is in the graphs library\n",
    "                if truth_table_int not in precomputed_graphs_2_input:\n",
    "                    continue  # Skip the rest of the iteration if no replacement graph is found\n",
    "\n",
    "                associated_graphs = precomputed_graphs_2_input[truth_table_int]\n",
    "                selected_graph_index = random.choice(associated_graphs)\n",
    "                replacement_graph = graphs_library_2_input[selected_graph_index]  \n",
    "\n",
    "            elif select_cut_size_n == 3:\n",
    "                #print(\"select_cut_size_n: \", select_cut_size_n)\n",
    "                # Check if the truth table integer is in the graphs library\n",
    "                if truth_table_int not in precomputed_graphs_3_input:\n",
    "                    continue  # Skip the rest of the iteration if no replacement graph is found\n",
    "\n",
    "                associated_graphs = precomputed_graphs_3_input[truth_table_int]\n",
    "                selected_graph_index = random.choice(associated_graphs)\n",
    "                replacement_graph = graphs_library_3_input[selected_graph_index]        \n",
    "                \n",
    "\n",
    "            elif select_cut_size_n == 4:\n",
    "                #print(\"select_cut_size_n: \", select_cut_size_n)\n",
    "                # Check if the truth table integer is in the graphs library\n",
    "                if truth_table_int not in precomputed_graphs_4_input:\n",
    "                    continue  # Skip the rest of the iteration if no replacement graph is found\n",
    "\n",
    "                associated_graphs = precomputed_graphs_4_input[truth_table_int]\n",
    "                selected_graph_index = random.choice(associated_graphs)\n",
    "                replacement_graph = graphs_library_4_input[selected_graph_index]                           \n",
    "                \n",
    "\n",
    "            if calculate_truth_table(subgraph) != calculate_truth_table(replacement_graph):\n",
    "                # If the truth tables do not match, raise an exception\n",
    "                raise ValueError(\"The truth tables of subgraph and replacement do not match.\")\n",
    "\n",
    "            new_solution = substitute_subgraph(current_solution, subgraph, replacement_graph)\n",
    "\n",
    "            node_with_more_than_two_incoming_edges = any(new_solution.in_degree(node) > 2 for node in new_solution.nodes()) #check if any gate has more than 2 inputs\n",
    "\n",
    "            if node_with_more_than_two_incoming_edges:\n",
    "                print(\"There is at least one node with more than two incoming edges.\")\n",
    "                print(\"Nodes with more than 2 incoming edges:\", node_with_more_than_two_incoming_edges)\n",
    "                print(\"target_node\", target_node)\n",
    "                visualize_graph_rewriting(current_solution, highlight_nodes=cut, title=\"current_solution\")\n",
    "                visualize_graph_rewriting(new_solution, highlight_nodes=cut, title=\"new_solution\")\n",
    "                visualize_graph_rewriting(subgraph, highlight_nodes=cut, title=\"subgraph\")\n",
    "                visualize_graph_rewriting(replacement_graph, highlight_nodes=cut, title=\"replacement_graph\")\n",
    "\n",
    "            # Check if new solution is 3-input 1-output\n",
    "            entry_nodes = [node for node in new_solution.nodes() if new_solution.in_degree(node) == 0]\n",
    "            exit_nodes = [node for node in new_solution.nodes() if new_solution.out_degree(node) == 0]\n",
    "\n",
    "            # Check if the counts match the specified criteria\n",
    "            has_three_entry_nodes = len(entry_nodes) == 4\n",
    "            has_one_exit_node = len(exit_nodes) == 1\n",
    "\n",
    "            if not has_three_entry_nodes or not has_one_exit_node:\n",
    "                print(\"BUG!\")\n",
    "                print(\"entry_nodes: \", entry_nodes)\n",
    "                print(\"exit_nodes: \", exit_nodes)\n",
    "\n",
    "            if calculate_truth_table_v2(current_solution) != calculate_truth_table_v2(new_solution):\n",
    "                # If the truth tables do not match, raise an exception\n",
    "                print(\"target_node\", target_node)\n",
    "                print(\"cut\", cut)\n",
    "                raise ValueError(\"The truth tables before and after rewriting do not match.\")\n",
    "\n",
    "            # Append new_solution only if it is not isomorphic to any graph in the list\n",
    "            if not any(nx.is_isomorphic(new_solution, existing_graph) for existing_graph in random_initial_states_list):\n",
    "                random_initial_states_list.append(new_solution)\n",
    "                pbar.update(1)  # Update the progress bar\n",
    "    \n",
    "    pbar.close()  # Close the progress bar when done\n",
    "    return random_initial_states_list  # Return the list of random initial states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a47679-77c5-4f4c-8225-5378ff28a745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05868e1-94dc-4c00-a1b8-69a5e25ec44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graphs_library_4_input\n",
    "#This is a small library\n",
    "'''\n",
    "with open('graphs_library_4_input_4_1.pkl', 'rb') as file:\n",
    "    graphs_library_4_input = pickle.load(file)\n",
    "\n",
    "# Load precomputed_graphs_4_input\n",
    "with open('precomputed_graphs_4_input_4_1.pkl', 'rb') as file:\n",
    "    precomputed_graphs_4_input = pickle.load(file)\n",
    "\n",
    "\n",
    "#This is a large library\n",
    "with open('graphs_library_4_input_pruned.pkl', 'rb') as file:\n",
    "    graphs_library_4_input = pickle.load(file)\n",
    "\n",
    "# Load precomputed_graphs_4_input\n",
    "with open('precomputed_graphs_4_input_pruned.pkl', 'rb') as file:\n",
    "    precomputed_graphs_4_input = pickle.load(file)\n",
    "'''\n",
    "\n",
    "#This is a large library with pruning, all ABC graphs, no additional keys\n",
    "with open('/home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/graphs_library_4_input_4_3_pruned.pkl', 'rb') as file:\n",
    "    graphs_library_4_input = pickle.load(file)\n",
    "\n",
    "# Load precomputed_graphs_4_input\n",
    "with open('/home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/precomputed_graphs_4_input_4_3_pruned.pkl', 'rb') as file:\n",
    "    precomputed_graphs_4_input = pickle.load(file)  \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# Load graphs_library_3_input\n",
    "with open('/home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/graphs_library_3_input_3_7.pkl', 'rb') as file:\n",
    "    graphs_library_3_input = pickle.load(file)\n",
    "\n",
    "# Load precomputed_graphs_3_input\n",
    "with open('/home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/precomputed_graphs_3_input_3_7.pkl', 'rb') as file:\n",
    "    precomputed_graphs_3_input = pickle.load(file)\n",
    "\n",
    "\n",
    "\n",
    "# Library of 2-input 1-output\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# Load graphs_library_2_input\n",
    "with open('/home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/graphs_library_2_input.pkl', 'rb') as file:\n",
    "    graphs_library_2_input = pickle.load(file)\n",
    "\n",
    "# Load precomputed_graphs_2_input\n",
    "with open('/home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/precomputed_graphs_2_input.pkl', 'rb') as file:\n",
    "    precomputed_graphs_2_input = pickle.load(file)\n",
    "\n",
    "\n",
    "# Library of 1-input 1-output\n",
    "# \n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# Load graphs_library_1_input\n",
    "with open('/home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/graphs_library_1_input.pkl', 'rb') as file:\n",
    "    graphs_library_1_input = pickle.load(file)\n",
    "\n",
    "# Load precomputed_graphs_1_input\n",
    "with open('/home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/precomputed_graphs_1_input.pkl', 'rb') as file:\n",
    "    precomputed_graphs_1_input = pickle.load(file)\n",
    "\n",
    "\n",
    "# # Load unoptimized graphs\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# Load NIGs_unoptimized_library_3_input_1_output\n",
    "with open('/home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/NIGs_unoptimized_library_3_input_1_output.pkl', 'rb') as file:\n",
    "    NIGs_unoptimized_library_3_input_1_output = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ebe3f0-c228-4d57-acdc-f7ffcfc8b27f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_graph_structure(G):\n",
    "    \"\"\"\n",
    "    Print adjacency list and attributes of a NetworkX graph.\n",
    "    \n",
    "    Parameters:\n",
    "    G (nx.Graph): A NetworkX graph object\n",
    "    \"\"\"\n",
    "    # Print adjacency list\n",
    "    print(\"\\n=== Adjacency List ===\")\n",
    "    for node in G.nodes():\n",
    "        neighbors = list(G.neighbors(node))\n",
    "        print(f\"Node {node} -> {neighbors}\")\n",
    "    \n",
    "    # Print node attributes\n",
    "    print(\"\\n=== Node Attributes ===\")\n",
    "    for node, attrs in G.nodes(data=True):\n",
    "        print(f\"Node {node}:\", attrs if attrs else \"No attributes\")\n",
    "    \n",
    "    # Print edge attributes\n",
    "    print(\"\\n=== Edge Attributes ===\")\n",
    "    for u, v, attrs in G.edges(data=True):\n",
    "        print(f\"Edge {u}-{v}:\", attrs if attrs else \"No attributes\")\n",
    "\n",
    "def plot_graph(G, layout='spring', node_color='lightblue', node_size=500, \n",
    "               with_labels=True, font_size=10, edge_color='gray', \n",
    "               title='Network Graph'):\n",
    "    \"\"\"\n",
    "    Plot a NetworkX graph with customizable options.\n",
    "    \n",
    "    Parameters:\n",
    "    G (nx.Graph): NetworkX graph\n",
    "    layout (str): Layout type ('spring', 'circular', 'random', 'shell')\n",
    "    node_color (str): Color of nodes\n",
    "    node_size (int): Size of nodes\n",
    "    with_labels (bool): Whether to show node labels\n",
    "    font_size (int): Size of label font\n",
    "    edge_color (str): Color of edges\n",
    "    title (str): Title of the plot\n",
    "    \"\"\"\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Choose layout\n",
    "    if layout == 'spring':\n",
    "        pos = nx.spring_layout(G)\n",
    "    elif layout == 'circular':\n",
    "        pos = nx.circular_layout(G)\n",
    "    elif layout == 'random':\n",
    "        pos = nx.random_layout(G)\n",
    "    elif layout == 'shell':\n",
    "        pos = nx.shell_layout(G)\n",
    "    else:\n",
    "        pos = nx.spring_layout(G)  # default to spring layout\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw(G, pos,\n",
    "            node_color=node_color,\n",
    "            node_size=node_size,\n",
    "            with_labels=with_labels,\n",
    "            font_size=font_size,\n",
    "            edge_color=edge_color,\n",
    "            font_weight='bold')\n",
    "    \n",
    "    # Draw edge labels if they exist\n",
    "    edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "    if edge_labels:\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt        \n",
    "        \n",
    "def plot_directed_graph(G, **kwargs):\n",
    "    plt = plot_graph(G, **kwargs)\n",
    "    # Get the axes object\n",
    "    ax = plt.gca()\n",
    "    # Clear the current plot\n",
    "    ax.clear()\n",
    "    # Draw the directed graph with arrows\n",
    "    nx.draw(G, nx.spring_layout(G), \n",
    "           with_labels=True,\n",
    "           node_color=kwargs.get('node_color', 'lightblue'),\n",
    "           node_size=kwargs.get('node_size', 500),\n",
    "           arrows=True,  # This adds the direction arrows\n",
    "           arrowsize=20)\n",
    "    plt.title(kwargs.get('title', 'Directed Graph'))\n",
    "    return plt\n",
    "\n",
    "#print_graph_structure(G)\n",
    "#plot_directed_graph(G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa776f-48b7-42e1-9211-71e6711ea4a7",
   "metadata": {},
   "source": [
    "### 4-input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "650af7ea-72b3-425d-b01e-6a9a865e4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_pickle(filename):\n",
    "    \"\"\"\n",
    "    Load a graph from a pickle file and convert back to NetworkX format.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Pickle file to load\n",
    "        \n",
    "    Returns:\n",
    "        nx.DiGraph: Reconstructed graph\n",
    "    \"\"\"\n",
    "    # Load the list from pickle\n",
    "    with open(filename, 'rb') as f:\n",
    "        graph_list = pickle.load(f)\n",
    "    \n",
    "    # Extract components\n",
    "    num_nodes, edges, node_attrs = graph_list\n",
    "    \n",
    "    # Create new graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes with attributes\n",
    "    for node, attr in node_attrs.items():\n",
    "        if attr is not None:\n",
    "            G.add_node(node, type=attr)\n",
    "        else:\n",
    "            G.add_node(node)\n",
    "    \n",
    "    # Add edges\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b133ad-dcf5-4570-8675-ab9b1d0aa3fb",
   "metadata": {},
   "source": [
    "### Top performing approach ABC many initial graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b2333-f153-4de7-a02c-455b22369ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b647b9b-ee31-40c3-90c3-7c9baf58c959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "64594\n"
     ]
    }
   ],
   "source": [
    "# Load graphs_library_4_input_ABC\n",
    "with open('/home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/4_input_precomputed_graphs/graphs_library_4_input_ABC.pkl', 'rb') as file:\n",
    "    graphs_library_4_input_ABC = pickle.load(file)\n",
    "\n",
    "# Verify the loaded data\n",
    "print(type(graphs_library_4_input_ABC))  # Should be a dict\n",
    "print(len(graphs_library_4_input_ABC))  # Number of elements in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d4d7a92-8b8a-444d-ab09-5eece4c1ec3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def iterative_optimization_without_persisting_OR(\n",
    "    G,\n",
    "    number_of_iterations,\n",
    "    number_of_graphs_per_iteration,\n",
    "    N_best,\n",
    "    precomputed_graphs_1_input,\n",
    "    graphs_library_1_input,\n",
    "    precomputed_graphs_2_input,\n",
    "    graphs_library_2_input,\n",
    "    precomputed_graphs_3_input,\n",
    "    graphs_library_3_input,\n",
    "    precomputed_graphs_4_input,\n",
    "    graphs_library_4_input,\n",
    "    plot = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform multiple iterations of the optimization flow:\n",
    "      1) Generate random states from the current set of graphs.\n",
    "      2) Check for implicit OR rewriting (only for computing energy).\n",
    "      3) Compute energy, store the best N *original* graphs (unrewritten).\n",
    "      4) Repeat.\n",
    "\n",
    "    We do NOT feed the rewritten graphs back into generate_random_initial_states_multi_input.\n",
    "    We only do rewriting to measure potential improvement in \"energy\".\n",
    "\n",
    "    Additionally, track and plot the best energy at each iteration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.DiGraph\n",
    "        The initial directed acyclic graph (DAG).\n",
    "    number_of_iterations : int\n",
    "        How many times to repeat the optimization cycle.\n",
    "    number_of_graphs_per_iteration : int\n",
    "        How many new graphs to generate in each iteration.\n",
    "    N_best : int\n",
    "        How many best (lowest-energy) graphs to keep for the next iteration.\n",
    "    precomputed_graphs_... : dict\n",
    "        Libraries for subgraph replacement.\n",
    "    graphs_library_... : dict\n",
    "        Corresponding stored graphs for subgraph replacement.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The final set of best original graphs (unrewritten).\n",
    "    \"\"\"\n",
    "\n",
    "    # Start with a single-graph list\n",
    "    current_graphs = [G.copy()]\n",
    "\n",
    "    # List to store the best energy at each iteration for plotting\n",
    "    best_energies = []\n",
    "\n",
    "    for iteration in range(number_of_iterations):\n",
    "        print(f\"\\n=== Iteration {iteration+1} / {number_of_iterations} ===\")\n",
    "\n",
    "        # 1) Generate new states from the current set\n",
    "        #    NOTE: your function should already return the seeds plus new solutions\n",
    "        all_new_graphs = generate_random_initial_states_multi_input(\n",
    "            current_graphs,\n",
    "            number_of_graphs_per_iteration,\n",
    "            precomputed_graphs_1_input,\n",
    "            graphs_library_1_input,\n",
    "            precomputed_graphs_2_input,\n",
    "            graphs_library_2_input,\n",
    "            precomputed_graphs_3_input,\n",
    "            graphs_library_3_input,\n",
    "            precomputed_graphs_4_input,\n",
    "            graphs_library_4_input\n",
    "        )\n",
    "\n",
    "        # Because generate_random_initial_states_multi_input already includes\n",
    "        # the original 'current_graphs', we do NOT need to add them again.\n",
    "        candidate_graphs_original = all_new_graphs\n",
    "\n",
    "        # 2) For each candidate, apply OR rewriting *only* to compute energy\n",
    "        energy_evaluations = []\n",
    "        for g_candidate in tqdm(candidate_graphs_original, desc=\"Evaluating Implicit OR\"):\n",
    "\n",
    "            # Identify output node (assuming 1)\n",
    "            exit_nodes = [n for n in g_candidate.nodes() if g_candidate.out_degree(n) == 0]\n",
    "            if not exit_nodes:\n",
    "                energy_evaluations.append((g_candidate, float('inf')))\n",
    "                continue\n",
    "\n",
    "            output_node = exit_nodes[0]\n",
    "            size_input_to_OR_gate = 2\n",
    "\n",
    "            # Check potential implicit OR\n",
    "            implicit_OR_results = check_implicit_OR_existence_v2(\n",
    "                g_candidate, output_node, size_input_to_OR_gate\n",
    "            )\n",
    "\n",
    "            max_removal = 0\n",
    "            max_implicit_OR_key = None\n",
    "\n",
    "            for key, value in implicit_OR_results.items():\n",
    "                if (value['is_there_an_implicit_OR'] and \n",
    "                    value['number_of_nodes_available_for_removal'] > max_removal):\n",
    "                    max_removal = value['number_of_nodes_available_for_removal']\n",
    "                    max_implicit_OR_key = key\n",
    "\n",
    "            # Temporarily rewrite (for energy measurement only)\n",
    "            if max_implicit_OR_key is not None:\n",
    "                cut  = implicit_OR_results[max_implicit_OR_key]['cut']\n",
    "                cone = implicit_OR_results[max_implicit_OR_key]['cone']\n",
    "                g_rewritten = add_implicit_OR_to_dag_v2(\n",
    "                    g_candidate, output_node, cut, cone\n",
    "                )\n",
    "                # example energy measure: number_of_nodes() minus 4 input + 1 output\n",
    "                energy_value = len(g_rewritten.nodes()) - 4 - 1\n",
    "            else:\n",
    "                energy_value = len(g_candidate.nodes()) - 4 - 1\n",
    "\n",
    "            # Store (original graph, energy_of_temporary_rewritten)\n",
    "            energy_evaluations.append((g_candidate, energy_value))\n",
    "\n",
    "        # 3) Sort by energy and keep the best N original graphs\n",
    "        energy_evaluations.sort(key=lambda x: x[1])  # ascending by energy\n",
    "        best_pairs = energy_evaluations[:N_best]\n",
    "\n",
    "        # Record best energy for plotting\n",
    "        best_energy_this_iter = best_pairs[0][1]\n",
    "        best_energies.append(best_energy_this_iter)\n",
    "\n",
    "        # Replace current_graphs with the best N for the next iteration\n",
    "        current_graphs = [p[0] for p in best_pairs]\n",
    "\n",
    "        \n",
    "    # Finally, plot best energy vs. iteration\n",
    "    if plot:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(range(1, number_of_iterations+1), best_energies, marker='o')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Best Energy')\n",
    "        plt.title('Best Graph Energy vs. Iteration')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    # Return final best set\n",
    "    return current_graphs\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22245e57-e9be-44d7-8b4b-75ad5c8706ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "743be7cc-18fc-4e1a-9b40-311a6c43139e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For key 400, initial number of gates: 16\n",
      "\n",
      "=== Iteration 1 / 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Random Initial States:   0%|          | 0/1000 [00:00<?, ?state/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Random Initial States: 100%|██████████| 1000/1000 [00:27<00:00, 36.29state/s]\n",
      "Evaluating Implicit OR: 100%|██████████| 1001/1001 [01:01<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Iteration 2 / 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Random Initial States: 100%|█████████▉| 996/1000 [00:25<00:00, 39.36state/s]\n",
      "Evaluating Implicit OR: 100%|██████████| 1001/1001 [00:47<00:00, 21.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Iteration 3 / 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Random Initial States: 100%|█████████▉| 996/1000 [00:33<00:00, 29.59state/s]\n",
      "Evaluating Implicit OR: 100%|██████████| 1001/1001 [01:23<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Iteration 4 / 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Random Initial States: 100%|█████████▉| 996/1000 [00:27<00:00, 35.95state/s]\n",
      "Evaluating Implicit OR: 100%|██████████| 1001/1001 [00:54<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Iteration 5 / 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Random Initial States: 100%|█████████▉| 996/1000 [00:25<00:00, 38.92state/s]\n",
      "Evaluating Implicit OR: 100%|██████████| 1001/1001 [00:45<00:00, 22.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For key 401, initial number of gates: 8\n",
      "\n",
      "=== Iteration 1 / 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Random Initial States: 100%|██████████| 1000/1000 [00:23<00:00, 42.56state/s]\n",
      "Evaluating Implicit OR: 100%|██████████| 1001/1001 [00:19<00:00, 51.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Iteration 2 / 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Random Initial States: 100%|█████████▉| 996/1000 [00:19<00:00, 51.73state/s]\n",
      "Evaluating Implicit OR: 100%|██████████| 1001/1001 [00:21<00:00, 46.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Iteration 3 / 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Random Initial States:  65%|██████▌   | 650/1000 [00:27<07:47,  1.34s/state] "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for value_decimal, G in graphs_library_4_input_ABC.items():\n",
    "    # Calculate initial number of gates\n",
    "    initial_num_gates = G.number_of_nodes() - 5\n",
    "\n",
    "    # Skip if the number of gates isn't 6 or 7\n",
    "    #if initial_num_gates not in (6, 7, 8, 9, 10, 11, 12):\n",
    "    #    continue\n",
    "        \n",
    "    \n",
    "    #if not (0 <= value_decimal <= 100):\n",
    "    #    continue\n",
    "    if value_decimal not in range(400, 500):\n",
    "        continue\n",
    "    \n",
    "    print(f\"For key {value_decimal}, initial number of gates: {initial_num_gates}\")\n",
    "\n",
    "    # Copy and run your iterative optimization\n",
    "    Gcopy = G.copy()\n",
    "    number_of_iterations = 5\n",
    "    number_of_graphs_per_iteration = 1000\n",
    "    N_best = 5\n",
    "\n",
    "    final_graphs = iterative_optimization_without_persisting_OR(\n",
    "        Gcopy,\n",
    "        number_of_iterations,\n",
    "        number_of_graphs_per_iteration,\n",
    "        N_best,\n",
    "        precomputed_graphs_1_input,\n",
    "        graphs_library_1_input,\n",
    "        precomputed_graphs_2_input,\n",
    "        graphs_library_2_input,\n",
    "        precomputed_graphs_3_input,\n",
    "        graphs_library_3_input,\n",
    "        precomputed_graphs_4_input,\n",
    "        graphs_library_4_input,\n",
    "        plot = False,\n",
    "    )\n",
    "\n",
    "    # Find the smallest number of gates among all final_graphs\n",
    "    lowest_gates = float('inf')\n",
    "    for final_G in final_graphs:\n",
    "        current_gates = final_G.number_of_nodes() - 5\n",
    "        if current_gates < lowest_gates:\n",
    "            lowest_gates = current_gates\n",
    "\n",
    "    # Store your results in a dictionary\n",
    "    results[value_decimal] = {\n",
    "        \"initial_num_gates\": initial_num_gates,\n",
    "        \"lowest_gates\": lowest_gates,\n",
    "        \"final_graphs\": final_graphs\n",
    "    }\n",
    "\n",
    "# Now 'results' contains:\n",
    "#   - initial_num_gates (only if it was 6 or 7)\n",
    "#   - lowest_gates\n",
    "#   - final_graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc76ca9-28ca-48a2-b872-b3394d639f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- 1) Pickle the full `results` dict ---------- #\n",
    "out_dir = Path(\"screening_for_keys_where_ABC_is_outperformed\")\n",
    "out_dir.mkdir(exist_ok=True)          # create a folder if it isn’t there\n",
    "pickle_path = out_dir / \"screening_for_keys_where_ABC_is_outperformed_initial_num_gates_all_keys400_499.pkl\"\n",
    "\n",
    "with open(pickle_path, \"wb\") as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(f\"[✓] Saved full results dict → {pickle_path.resolve()}\")\n",
    "\n",
    "# ---------- 2) Write the summary CSV, now with Δ column ---------- #\n",
    "csv_path = out_dir / \"screening_for_keys_where_ABC_is_outperformed_initial_num_gates6_all_keys400_499.csv\"\n",
    "fieldnames = [\"value_decimal\", \"initial_num_gates\", \"lowest_gates\", \"delta_gates\"]  # added delta_gates\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for value_decimal, payload in results.items():\n",
    "        initial_g = payload[\"initial_num_gates\"]\n",
    "        lowest_g  = payload[\"lowest_gates\"]\n",
    "        delta_g   = initial_g - lowest_g           # positive means improvement\n",
    "\n",
    "        writer.writerow(\n",
    "            {\n",
    "                \"value_decimal\":   value_decimal,\n",
    "                \"initial_num_gates\": initial_g,\n",
    "                \"lowest_gates\":     lowest_g,\n",
    "                \"delta_gates\":      delta_g,\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(f\"[✓] Saved summary CSV     → {csv_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234af648-f0c2-4cfa-8e56-5ce33d5a6a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea919a40-5146-45c6-8622-a5052f84e444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74412098-b057-4520-9cc3-0481bc9e06e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e4a01-c9da-49a3-a70b-d5a779fb87ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
