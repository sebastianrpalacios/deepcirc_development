{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654d8e2b-1b1e-4d8d-82fa-7321448c04d0",
   "metadata": {},
   "source": [
    "Script to build the action catalog v1 (old version, deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a376bdb7-53f3-4ed0-8f15-d2018e5db8f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building catalog: 100%|██████████| 154103/154103 [07:26<00:00, 345.39graph/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog size: 15928 unique iso graphs\n",
      "Catalog saved to /home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/action_catalog.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Build the iso-only action catalog once and save to disk.\n",
    "\n",
    "Run this script OFFLINE (or once per job) after your graph libraries are\n",
    "loaded. It deduplicates graphs by directed isomorphism, creates the lookup\n",
    "(num_inputs, tt_int) → action_ids, and writes a pickle:\n",
    "\n",
    "    action_catalog.pkl  # {\"graphs\": UNIQUE_GRAPHS, \"lookup\": TTABLE_TO_ACTIONS}\n",
    "\n",
    "Set env var ACTION_CATALOG_PATH if you save it elsewhere.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import pickle, warnings\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from networkx.algorithms import weisfeiler_lehman_graph_hash as _wl_hash\n",
    "\n",
    "from utils5 import calculate_truth_table  # <- import your existing TT helper\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Load graph libraries ------------------------------------------------------\n",
    "# Adjust these paths to your pickles\n",
    "# -----------------------------------------------------------------------------\n",
    "with open(\"graphs_library_1_input_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib1 = pickle.load(f)\n",
    "with open(\"graphs_library_2_input_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib2 = pickle.load(f)\n",
    "with open(\"graphs_library_3_input_3_7_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib3 = pickle.load(f)\n",
    "with open(\"graphs_library_4_input_4_3_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib4 = pickle.load(f)\n",
    "\n",
    "LIBRARIES_RAW: Dict[int, object] = {\n",
    "    1: graphs_lib1,\n",
    "    2: graphs_lib2,\n",
    "    3: graphs_lib3,\n",
    "    4: graphs_lib4,\n",
    "}\n",
    "\n",
    "# Convert dict->list if needed\n",
    "LIBRARIES: Dict[int, List[nx.DiGraph]] = {}\n",
    "for n_in, lib in LIBRARIES_RAW.items():\n",
    "    if isinstance(lib, dict):\n",
    "        LIBRARIES[n_in] = list(lib.values())\n",
    "    elif isinstance(lib, list):\n",
    "        LIBRARIES[n_in] = lib\n",
    "    else:\n",
    "        raise TypeError(f\"Library for {n_in}-input graphs must be list or dict\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Helpers -------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def _quick_hash(g: nx.DiGraph) -> str:\n",
    "    return _wl_hash(g.to_undirected(), node_attr=None, edge_attr=None)\n",
    "\n",
    "def _truth_key(g: nx.DiGraph) -> Tuple[int, int]:\n",
    "    tt = calculate_truth_table(g)\n",
    "    bits = \"\".join(str(o[0]) for _, o in sorted(tt.items()))\n",
    "    num_inputs = (len(tt).bit_length() - 1)\n",
    "    return (num_inputs, int(bits, 2))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Build catalog -------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "UNIQUE_GRAPHS: List[nx.DiGraph] = []\n",
    "TTABLE_TO_ACTIONS: Dict[Tuple[int, int], List[int]] = defaultdict(list)\n",
    "_bucket: Dict[str, List[int]] = defaultdict(list)\n",
    "\n",
    "all_graphs = [g for lib in LIBRARIES.values() for g in lib]\n",
    "non_graphs = 0\n",
    "for g in tqdm(all_graphs, desc=\"Building catalog\", unit=\"graph\"):\n",
    "    if not isinstance(g, nx.DiGraph):\n",
    "        non_graphs += 1\n",
    "        continue\n",
    "    qh = _quick_hash(g)\n",
    "    act_id = None\n",
    "    for cand in _bucket[qh]:\n",
    "        if nx.is_isomorphic(g, UNIQUE_GRAPHS[cand]):\n",
    "            act_id = cand\n",
    "            break\n",
    "    if act_id is None:\n",
    "        act_id = len(UNIQUE_GRAPHS)\n",
    "        UNIQUE_GRAPHS.append(g)\n",
    "        _bucket[qh].append(act_id)\n",
    "    TTABLE_TO_ACTIONS[_truth_key(g)].append(act_id)\n",
    "\n",
    "for k in TTABLE_TO_ACTIONS:\n",
    "    TTABLE_TO_ACTIONS[k] = list(dict.fromkeys(TTABLE_TO_ACTIONS[k]))\n",
    "\n",
    "print(f\"Catalog size: {len(UNIQUE_GRAPHS)} unique iso graphs\")\n",
    "if non_graphs:\n",
    "    warnings.warn(f\"Ignored {non_graphs} non-graph entries.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Save ----------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "out_path = Path(\"action_catalog_old.pkl\")\n",
    "with out_path.open(\"wb\") as f:\n",
    "    pickle.dump({\"graphs\": UNIQUE_GRAPHS, \"lookup\": TTABLE_TO_ACTIONS}, f)\n",
    "print(f\"Catalog saved to {out_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d27e4-647c-49f6-b8d0-923461472a19",
   "metadata": {},
   "source": [
    "Some testing scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55033b5e-b391-444e-b0fa-8787e55d4fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Directed Isomorphism Deduplication]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking directed isomorphisms: 100%|██████████| 154103/154103 [3:30:27<00:00, 12.20it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Found 15928 unique directed graphs\n",
      "\n",
      "[Undirected Isomorphism Deduplication]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking undirected isomorphisms:  14%|█▎        | 20897/154103 [20:21<4:15:33,  8.69it/s]"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---- If you run this independently, import or copy from build_action_catalog.py ----\n",
    "import pickle\n",
    "\n",
    "with open(\"graphs_library_1_input_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib1 = pickle.load(f)\n",
    "with open(\"graphs_library_2_input_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib2 = pickle.load(f)\n",
    "with open(\"graphs_library_3_input_3_7_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib3 = pickle.load(f)\n",
    "with open(\"graphs_library_4_input_4_3_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib4 = pickle.load(f)\n",
    "\n",
    "LIBRARIES_RAW = {\n",
    "    1: graphs_lib1,\n",
    "    2: graphs_lib2,\n",
    "    3: graphs_lib3,\n",
    "    4: graphs_lib4,\n",
    "}\n",
    "\n",
    "LIBRARIES = {\n",
    "    n_in: list(lib.values()) if isinstance(lib, dict) else lib\n",
    "    for n_in, lib in LIBRARIES_RAW.items()\n",
    "}\n",
    "\n",
    "# ---- Flatten the graphs ----\n",
    "all_graphs = [g for lib in LIBRARIES.values() for g in lib if isinstance(g, nx.DiGraph)]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Directed Isomorphism Deduplication\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n[Directed Isomorphism Deduplication]\")\n",
    "directed_unique = []\n",
    "for g in tqdm(all_graphs, desc=\"Checking directed isomorphisms\"):\n",
    "    for h in directed_unique:\n",
    "        if nx.is_isomorphic(g, h):\n",
    "            break\n",
    "    else:\n",
    "        directed_unique.append(g)\n",
    "\n",
    "print(f\"→ Found {len(directed_unique)} unique directed graphs\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Undirected Isomorphism Deduplication\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n[Undirected Isomorphism Deduplication]\")\n",
    "undirected_unique = []\n",
    "for g in tqdm(all_graphs, desc=\"Checking undirected isomorphisms\"):\n",
    "    g_undir = g.to_undirected()\n",
    "    for h in undirected_unique:\n",
    "        if nx.is_isomorphic(g_undir, h.to_undirected()):\n",
    "            break\n",
    "    else:\n",
    "        undirected_unique.append(g)\n",
    "\n",
    "print(f\"→ Found {len(undirected_unique)} unique undirected graphs\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Summary\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n[Summary]\")\n",
    "print(f\"Total input graphs:       {len(all_graphs)}\")\n",
    "print(f\"Unique (directed):        {len(directed_unique)}\")\n",
    "print(f\"Unique (undirected):      {len(undirected_unique)}\")\n",
    "print(f\"Graphs with identical structure when ignoring direction: {len(undirected_unique) - len(directed_unique)} more\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e3b22c-4fe7-4c68-bdac-45e9cae1b68f",
   "metadata": {},
   "source": [
    "Script to build the action catalog v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e6dcd-db20-45d0-81bb-58d4cd5e4605",
   "metadata": {},
   "source": [
    "This version avoids missing some key --> aid mappings by not assuming that the initial libraries have all the permutations of each unique graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc70c042-3da6-4f5b-9914-a8cd47cbc76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deduplicating (iso): 100%|██████████| 154103/154103 [06:05<00:00, 421.64graph/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique iso graphs: 15928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Storing all permutations: 100%|██████████| 15928/15928 [08:40<00:00, 30.58graph/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookup entries: 65539 (key → action list)\n",
      "Permutation-complete catalogue saved to /home/gridsan/spalacios/DRL1/supercloud-testing/ABC-and-PPO-testing1/action_catalog.pkl\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Build a permutation-complete action catalogue.\n",
    "\n",
    "Resulting pickle:\n",
    "    action_catalog.pkl   # {\"graphs\": UNIQUE_GRAPHS,\n",
    "                         #  \"lookup\": TTABLE_TO_ACTIONS}\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import pickle, warnings, itertools\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from networkx.algorithms import weisfeiler_lehman_graph_hash as _wl_hash\n",
    "\n",
    "from utils5 import calculate_truth_table_v2     # your existing helper\n",
    "# ---------------------------------------------------------------------\n",
    "# 1) Load graph libraries ---------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "with open(\"graphs_library_1_input_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib1 = pickle.load(f)\n",
    "with open(\"graphs_library_2_input_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib2 = pickle.load(f)\n",
    "with open(\"graphs_library_3_input_3_7_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib3 = pickle.load(f)\n",
    "with open(\"graphs_library_4_input_4_3_pruned.pkl\", \"rb\") as f:\n",
    "    graphs_lib4 = pickle.load(f)\n",
    "\n",
    "LIBRARIES_RAW: Dict[int, object] = {\n",
    "    1: graphs_lib1,\n",
    "    2: graphs_lib2,\n",
    "    3: graphs_lib3,\n",
    "    4: graphs_lib4,\n",
    "}\n",
    "\n",
    "# convert dict → list if needed\n",
    "LIBRARIES: Dict[int, List[nx.DiGraph]] = {}\n",
    "for n_in, lib in LIBRARIES_RAW.items():\n",
    "    if isinstance(lib, dict):\n",
    "        LIBRARIES[n_in] = list(lib.values())\n",
    "    elif isinstance(lib, list):\n",
    "        LIBRARIES[n_in] = lib\n",
    "    else:\n",
    "        raise TypeError(f\"Library for {n_in}-input graphs must be list or dict\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) Helpers -----------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "def _quick_hash(g: nx.DiGraph) -> str:\n",
    "    \"\"\"WL hash of the undirected shadow – fast iso pre-filter.\"\"\"\n",
    "    return _wl_hash(g.to_undirected(), node_attr=None, edge_attr=None)\n",
    "\n",
    "def _truth_key(g: nx.DiGraph) -> Tuple[int, int]:\n",
    "    \"\"\"(num_inputs, integer-encoded truth table).\"\"\"\n",
    "    tt = calculate_truth_table_v2(g)           # dict[input_tuple] → [out_bit]\n",
    "    bits = \"\".join(str(o[0]) for _, o in sorted(tt.items()))\n",
    "    num_inputs = (len(tt).bit_length() - 1)\n",
    "    return num_inputs, int(bits, 2)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) Deduplicate by isomorphism ---------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "UNIQUE_GRAPHS: List[nx.DiGraph] = []\n",
    "_iso_bucket: Dict[str, List[int]] = defaultdict(list)   # WL-hash → act_ids\n",
    "\n",
    "all_graphs = [g for lib in LIBRARIES.values() for g in lib]\n",
    "non_graphs = 0\n",
    "\n",
    "for g in tqdm(all_graphs, desc=\"Deduplicating (iso)\", unit=\"graph\"):\n",
    "    if not isinstance(g, nx.DiGraph):\n",
    "        non_graphs += 1\n",
    "        continue\n",
    "\n",
    "    qh = _quick_hash(g)\n",
    "    act_id = None\n",
    "    for cand in _iso_bucket[qh]:\n",
    "        if nx.is_isomorphic(g, UNIQUE_GRAPHS[cand]):\n",
    "            act_id = cand                      # already seen iso\n",
    "            break\n",
    "    if act_id is None:                         # new iso-class\n",
    "        act_id = len(UNIQUE_GRAPHS)\n",
    "        UNIQUE_GRAPHS.append(g)\n",
    "        _iso_bucket[qh].append(act_id)\n",
    "\n",
    "print(f\"Unique iso graphs: {len(UNIQUE_GRAPHS)}\")\n",
    "if non_graphs:\n",
    "    warnings.warn(f\"Ignored {non_graphs} non-graph entries.\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) Build permutation-complete lookup --------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "TTABLE_TO_ACTIONS: Dict[Tuple[int, int], List[int]] = defaultdict(list)\n",
    "\n",
    "for aid, g in enumerate(tqdm(UNIQUE_GRAPHS,\n",
    "                             desc=\"Storing all permutations\", unit=\"graph\")):\n",
    "    pins = [n for n in g if g.in_degree(n) == 0]\n",
    "\n",
    "    # iterate over ALL input-pin permutations\n",
    "    for perm in itertools.permutations(pins):\n",
    "        g_perm = nx.relabel_nodes(g, dict(zip(pins, perm)), copy=True)\n",
    "        key = _truth_key(g_perm)\n",
    "        TTABLE_TO_ACTIONS[key].append(aid)\n",
    "\n",
    "# deduplicate the action lists (they’re tiny – set→list is fine)\n",
    "for k, lst in TTABLE_TO_ACTIONS.items():\n",
    "    TTABLE_TO_ACTIONS[k] = sorted(set(lst))\n",
    "\n",
    "print(f\"Lookup entries: {len(TTABLE_TO_ACTIONS)} (key → action list)\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 5) Save --------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------\n",
    "out_path = Path(\"action_catalog.pkl\")\n",
    "with out_path.open(\"wb\") as f:\n",
    "    pickle.dump({\"graphs\": UNIQUE_GRAPHS, \"lookup\": TTABLE_TO_ACTIONS}, f)\n",
    "\n",
    "print(f\"Permutation-complete catalogue saved to {out_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f1df4-5a72-49c7-821b-bca4fa03844c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
